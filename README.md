# Custom Models, Layers, and Loss Functions with TensorFlow
## Week 1
Learn more about the Inception Model Architecture [klik](https://towardsdatascience.com/a-simple-guide-to-the-versions-of-the-inception-network-7fc52b863202)

Energy efficiency dataset [klik](https://archive.ics.uci.edu/ml/datasets/Energy+efficiency)

References about the Siamese network
-  [Learning a Similarity Metric Discriminatively, with Application to Face Verification](http://yann.lecun.com/exdb/publis/pdf/chopra-05.pdf) (Chopra, Hadsell, & LeCun, 2005)
-  [Similarity Learning with (or without) Convolutional Neural Network](http://slazebni.cs.illinois.edu/spring17/lec09_similarity.pdf)  (Chatterjee & Luo, n.d.)

Reference "The distance between two vectors" 
[The Distance Between Two Vectors](http://mathonline.wikidot.com/the-distance-between-two-vectors)

## Week 2
Huber Loss reference [link](https://en.wikipedia.org/wiki/Huber_loss)

Reference: Dimensionality reduction by Learning an Invariant Mapping
[Dimensionality Reduction by Learning an Invariant Mapping](http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf)

## Week 4
Understanding Residual networks [link](https://ai.googleblog.com/2016/06/wide-deep-learning-better-together-with.html)
Residual networks lectures (optional)
Lecture on [Residual Networks](https://www.coursera.org/lecture/convolutional-neural-networks/resnets-HAhz9) by Andrew Ng (part of [ 
Deep Learning Specialization](https://www.coursera.org/specializations/deep-learning), [Course 4: Convolutional Neural Networks](https://www.coursera.org/learn/convolutional-neural-networks)

## Week 5
TensorBoard visualization toolkit [link](https://www.tensorflow.org/tensorboard)
